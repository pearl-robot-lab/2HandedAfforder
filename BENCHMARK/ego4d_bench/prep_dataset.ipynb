{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import json\n",
    "from tqdm import trange"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "repo_path = \"/home/sjauhri/IAS_WS/EgoVis/2handedafforder_repo/\"\n",
    "dataset_folder = repo_path + \"BENCHMARK/ego4d_bench/bench_data/\"\n",
    "# original_frame_folder = repo_path + \"BENCHMARK/ego4d_bench/bench_data/\"\n",
    "# full_inpainted_frame_folder = repo_path + \"BENCHMARK/ego4d_bench/bench_data/\"\n",
    "out_folder = dataset_folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing videos:   0%|          | 0/8 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating viz images for annotation for video id 8f91bc0d-9ce7-4b31-aba7-dd59791917df\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing frames: 100%|██████████| 260/260 [00:06<00:00, 42.90it/s]\n",
      "Processing videos:  12%|█▎        | 1/8 [00:06<00:42,  6.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating viz images for annotation for video id 793a9c9d-327e-4457-9c40-e626b2208aae\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing frames: 100%|██████████| 92/92 [00:01<00:00, 59.47it/s]\n",
      "Processing videos:  25%|██▌       | 2/8 [00:07<00:20,  3.41s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating viz images for annotation for video id 114d86a7-2849-46de-8bb7-8fe1e1a48be8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing frames: 100%|██████████| 426/426 [00:10<00:00, 41.70it/s]\n",
      "Processing videos:  38%|███▊      | 3/8 [00:17<00:32,  6.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating viz images for annotation for video id 60b0ccb6-49f7-4a44-a70d-bf319217af50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing frames: 100%|██████████| 200/200 [00:04<00:00, 42.15it/s]\n",
      "Processing videos:  50%|█████     | 4/8 [00:22<00:23,  5.82s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating viz images for annotation for video id 1244d83b-fb99-469c-a943-354ac4d95361\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing frames: 100%|██████████| 409/409 [00:09<00:00, 42.24it/s]\n",
      "Processing videos:  62%|██████▎   | 5/8 [00:32<00:21,  7.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating viz images for annotation for video id 126fe8f1-226a-4161-ad6e-84f9e5baeb3a\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing frames: 100%|██████████| 773/773 [00:18<00:00, 40.86it/s]\n",
      "Processing videos:  75%|███████▌  | 6/8 [00:51<00:22, 11.19s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating viz images for annotation for video id 1134205f-6f03-47ac-bf8e-ae1453dc7fc9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing frames: 100%|██████████| 319/319 [00:07<00:00, 41.94it/s]\n",
      "Processing videos:  88%|████████▊ | 7/8 [00:58<00:10, 10.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating viz images for annotation for video id 11286c45-7869-4b84-81a5-7fcb9a247e9d\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing frames: 100%|██████████| 714/714 [00:16<00:00, 42.50it/s]\n",
      "Processing videos: 100%|██████████| 8/8 [01:15<00:00,  9.45s/it]\n"
     ]
    }
   ],
   "source": [
    "# Create viz images for annotation (affordance class + inpainted image + original image)\n",
    "for i in trange(len(os.listdir(dataset_folder)), desc=\"Processing videos\"):\n",
    "    video_dir = os.listdir(dataset_folder)[i]\n",
    "    print(f\"Generating viz images for annotation for video id {video_dir}\")\n",
    "\n",
    "    for f_i in trange(len(os.listdir(os.path.join(dataset_folder, video_dir))), desc=\"Processing frames\"):\n",
    "        frame_id = os.listdir(os.path.join(dataset_folder, video_dir))[f_i]\n",
    "        \n",
    "        # fetch the original video frame corresponding to this datapoint\n",
    "        # print(\"Frame ID: \", frame_id)\n",
    "        original_frame_file_path = os.path.join(dataset_folder, video_dir, frame_id, 'frame.png')\n",
    "        # inpainted frame\n",
    "        inpainted_frame_file_path = os.path.join(dataset_folder, video_dir, frame_id, 'inpainted_frame.png')\n",
    "        # get the affordance class from the json file\n",
    "        affordance_annotation_file_path = os.path.join(dataset_folder, video_dir, frame_id, \"annotation.json\")\n",
    "\n",
    "        # create new image by concatenating the inpainted image, original image and affordance class\n",
    "        inpainted_frame = cv2.imread(inpainted_frame_file_path)\n",
    "        # inpainted_frame = cv2.cvtColor(inpainted_frame, cv2.COLOR_BGR2RGB)\n",
    "        # Scale up inpainted image (to 512,512)\n",
    "        inpainted_frame = cv2.resize(inpainted_frame, (inpainted_frame.shape[1] * 2, inpainted_frame.shape[0] * 2))\n",
    "        original_frame = cv2.imread(original_frame_file_path)\n",
    "        # Scale down the original frame to 2/5th the size of the inpainted frame height\n",
    "        scaling_factor = (2.0/5.0) * inpainted_frame.shape[0] / original_frame.shape[0]\n",
    "        original_frame = cv2.resize(original_frame, (int(original_frame.shape[1] * scaling_factor), int(original_frame.shape[0] * scaling_factor)))\n",
    "        with open(affordance_annotation_file_path, 'r') as f:\n",
    "            annotation_data = json.load(f)\n",
    "            aff_class = annotation_data.get('narration', 'Unknown')\n",
    "            if '#unsure' in aff_class:\n",
    "                # replace with blank space\n",
    "                aff_class = aff_class.replace('#unsure', '')\n",
    "            # replace first four characters with 'person'\n",
    "            aff_class = 'person' + aff_class[4:]\n",
    "        if original_frame is not None and inpainted_frame is not None:\n",
    "            # Resize original frame to match the height of the inpainted frame\n",
    "            height_diff = inpainted_frame.shape[0] - original_frame.shape[0]\n",
    "            black_space = np.zeros((height_diff, original_frame.shape[1], 3), dtype=np.uint8)\n",
    "\n",
    "            # Add white text to the black space\n",
    "            font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "            font_scale = 1\n",
    "            font_color = (255, 255, 255)\n",
    "            thickness = 2\n",
    "            text = f\"Task:\"\n",
    "            text_size = cv2.getTextSize(text, font, font_scale, thickness)[0]\n",
    "            text_x = (black_space.shape[1] - text_size[0]) // 2\n",
    "            text_y = (black_space.shape[0] + text_size[1]) // 2  - 90\n",
    "            cv2.putText(black_space, text, (text_x, text_y), font, font_scale, font_color, thickness)\n",
    "            text = f\"{aff_class}\"\n",
    "            # Split the text into multiple lines if it doesn't fit in the width\n",
    "            max_width = black_space.shape[1]\n",
    "            words = text.split()\n",
    "            lines = []\n",
    "            current_line = words[0]\n",
    "\n",
    "            for word in words[1:]:\n",
    "                if cv2.getTextSize(current_line + ' ' + word, font, font_scale, thickness)[0][0] < max_width:\n",
    "                    current_line += ' ' + word\n",
    "                else:\n",
    "                    lines.append(current_line)\n",
    "                    current_line = word\n",
    "            lines.append(current_line)\n",
    "\n",
    "            y_offset = text_y + 40\n",
    "            for line in lines:\n",
    "                text_size = cv2.getTextSize(line, font, font_scale, thickness)[0]\n",
    "                text_x = (black_space.shape[1] - text_size[0]) // 2\n",
    "                cv2.putText(black_space, line, (text_x, y_offset), font, font_scale, font_color, thickness)\n",
    "                y_offset += text_size[1] + 10\n",
    "\n",
    "            # Add \"Example\" text just above the original frame\n",
    "            example_text = \"Example:\"\n",
    "            example_text_size = cv2.getTextSize(example_text, font, font_scale, thickness)[0]\n",
    "            example_text_x = (black_space.shape[1] - example_text_size[0]) // 2\n",
    "            example_text_y = black_space.shape[0] - 20\n",
    "            cv2.putText(black_space, example_text, (example_text_x, example_text_y), font, font_scale, font_color, thickness)\n",
    "            original_frame = np.vstack((black_space, original_frame))\n",
    "\n",
    "            benchmark_frame = np.concatenate((inpainted_frame, original_frame), axis=1)\n",
    "            benchmark_frame_path = os.path.join(dataset_folder, video_dir, frame_id, \"benchmark_frame.png\")\n",
    "            cv2.imwrite(benchmark_frame_path, benchmark_frame)\n",
    "            # print(f\"Saved benchmark frame to {benchmark_frame_path}\")\n",
    "        else:\n",
    "            raise Exception(\"Original or inpainted frame is not found\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "2handedafforder",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
